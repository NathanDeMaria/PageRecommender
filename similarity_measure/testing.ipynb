{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Text\n",
    "I found two \"similar\" articles and stored them as an initial starting point. This is my attempt to try and get a similarity measure between the articles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above doesnt work so well so I am going to try using beautiful soup now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # To get everything  \n",
    "import urllib\n",
    "import re \n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "url1 = 'https://timdettmers.wordpress.com/2015/07/27/brain-vs-deep-learning-singularity/'\n",
    "url2 = 'http://neuralnetworksanddeeplearning.com/chap6.html'\n",
    "\n",
    "html = urllib.urlopen('https://timdettmers.wordpress.com/2015/07/27/brain-vs-deep-learning-singularity/').read()\n",
    "soup = BeautifulSoup(html)\n",
    "texts = soup.findAll(text=True)\n",
    "\n",
    "def visible(element):\n",
    "    if element.parent.name in ['style', 'script', '[document]', 'head', 'title']:\n",
    "        return False\n",
    "    elif re.match('<!--.*-->', str(unidecode(element))):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "visible_texts = filter(visible, texts)\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "1890\n"
     ]
    }
   ],
   "source": [
    "print type(visible_texts)\n",
    "print len(visible_texts)\n",
    "\n",
    "if(verbose):\n",
    "    for item in visible_texts:\n",
    "        print item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be a lot of white space lines so trying to get rid of those. All of the weird non-text bits I am just going to assume arent important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "new_vis_text = filter(lambda x: not(x.isspace()) and (x[0] not in string.punctuation) and not(x.isdigit()) and (x[0].isalnum()), visible_texts)\n",
    "print len(new_vis_text)\n",
    "\n",
    "if(verbose):\n",
    "    for item in new_vis_text:\n",
    "        print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is much cleaner and easier to work with but is in a list.\n",
    "#Need to convert this back into 1 big string to send into ngrams module to construct ngrams for classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
